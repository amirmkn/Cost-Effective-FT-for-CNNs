import torch
import torch.nn as nn
from torch import jit

class VulnerabilityAnalyzer:

    def __init__(self, model, device):
        self.model = model.to(device)
        self.device = device
        self.model.eval()

    def analyze(self, dataloader, max_batches=1):
        vuln = {}

        target_modules = []
        for name, module in self.model.named_modules():
            if isinstance(module, (nn.Conv2d, nn.Linear)):
                module.weight.requires_grad_(True)
                target_modules.append((name, module))

        for b_idx, (x, y) in enumerate(dataloader):
            if b_idx >= max_batches:
                break

            x, y = x.to(self.device), y.to(self.device)

            for b in range(x.size(0)):
                self.model.zero_grad()
                out = self.model(x[b].unsqueeze(0))
                num_classes = out.size(1)
                target_class = y[b]
                Zt = out[0, target_class]

                grad_t = torch.autograd.grad(
                    Zt,
                    [m.weight for _, m in target_modules],
                    retain_graph=True
                )

                # Launch parallel grad computations for each non‑target class
                futures = []
                for i in range(num_classes):
                    if i == target_class:
                        continue
                    Zi = out[0, i]
                    denom = (Zi - Zt).detach().pow(2) + 1e-12
                    futures.append(
                        jit.fork(self._compute_grad_i, Zi, target_modules, denom, grad_t)
                    )

                # Wait for all async jobs
                for fut in futures:
                    partial_vuln = jit.wait(fut)
                    # Aggregate results
                    for name, score in partial_vuln.items():
                        if name not in vuln:
                            vuln[name] = score
                        else:
                            vuln[name] += score

                del grad_t
                torch.cuda.empty_cache()

        # Post‑process results
        result = {}
        for k, v in vuln.items():
            vals = v.cpu().tolist()
            sorted_idx = sorted(range(len(vals)), key=lambda i: vals[i], reverse=True)
            result[k] = {"scores": vals, "sorted_idx": sorted_idx}
        return result

    def _compute_grad_i(self, Zi, target_modules, denom, grad_t):
        grad_i = torch.autograd.grad(
            Zi, [m.weight for _, m in target_modules],
            retain_graph=True
        )
        partial_vuln = {}
        for (name, module), g_i, g_t in zip(target_modules, grad_i, grad_t):
            g_diff = g_i - g_t
            if isinstance(module, nn.Conv2d):
                score = g_diff.pow(2).sum(dim=(1,2,3)) / denom
            else:
                score = g_diff.pow(2).sum(dim=1) / denom
            partial_vuln[name] = score.detach()
        return partial_vuln
